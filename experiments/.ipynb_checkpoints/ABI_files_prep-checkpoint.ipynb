{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare ABI files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ABI files are not split per word/phrase; one file can contain multiple words or phrases. Here, some code is written to split the audio files using the given time stamps in the ABI archive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mbrm_001\u001b[m\u001b[m \u001b[34mean_001\u001b[m\u001b[m \u001b[34mgla_001\u001b[m\u001b[m \u001b[34mlan_001\u001b[m\u001b[m \u001b[34mncl_001\u001b[m\u001b[m \u001b[34mroi_001\u001b[m\u001b[m \u001b[34msse_001\u001b[m\u001b[m\n",
      "\u001b[34mcrn_001\u001b[m\u001b[m \u001b[34meyk_001\u001b[m\u001b[m \u001b[34milo_001\u001b[m\u001b[m \u001b[34mlvp_001\u001b[m\u001b[m \u001b[34mnwa_001\u001b[m\u001b[m \u001b[34mshl_001\u001b[m\u001b[m \u001b[34muls_001\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import join, expanduser, exists, basename\n",
    "DATA_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/data\", \"ABI-1\")\n",
    "!ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = ['gla_001/female/joh001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of speakers to process in ABI corpus in 'accent/gender/speaker' format\n",
    "speakers = ['sse_001/male/rkm001', 'sse_001/female/wjh001', 'gla_001/male/wht001', 'gla_001/female/mad001', \n",
    "            'shl_001/male/cnb001', 'shl_001/female/jmr001', 'lan_001/male/gxi002', 'lan_001/female/jxd001',\n",
    "            'ean_001/male/htl001', 'ean_001/female/nxp001', 'roi_001/male/gwd001', 'roi_001/female/mgm001', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split file using (start, end) times and save using file_name+000.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the audio files based on the abs path to a speaker (abs_path_spk) and timestamp file\n",
    "def split_audio(abs_path_spk, file):\n",
    "    # given an absolute path to a file with start/stop timestamps and a word/phrase,\n",
    "    # gives a list of [start, stop] timestamps\n",
    "    with open(join(abs_path_spk, file)) as f:\n",
    "        timestamps = []\n",
    "        text = [] # list of words/phrases said at each time stamp\n",
    "        for line in f.readlines():\n",
    "            split_line = line.split()\n",
    "            timestamps.append(split_line[:2])\n",
    "            line_text = ' '.join(split_line[2:])\n",
    "            text.append(line_text)\n",
    "\n",
    "    exp_name = basename(file).split('_')[0] # get experiment name from timestamp file to make new folder\n",
    "    exp_folder = join(abs_path_spk, exp_name) # abs path to experiment folder\n",
    "    if not exists(exp_folder):\n",
    "        makedirs(exp_folder)\n",
    "    \n",
    "    abs_path_audio = join(abs_path_spk, exp_name + '_CT.wav') # all original audios end in '_CT.wav'\n",
    "    audio = AudioSegment.from_wav(abs_path_audio)\n",
    "\n",
    "    word_count = Counter()\n",
    "    for idx, ts in enumerate(timestamps):\n",
    "        start, end = float(ts[0]) * 1000, float(ts[1]) * 1000 #pydub requires milliseconds\n",
    "        audio_chunk = audio[start:end]  \n",
    "        if exp_name.startswith('cw'): # only check wordlists since they are the most variable \n",
    "            test_word = text[idx] # get the text at timestamp (e.g. 'hood', 'hawd')\n",
    "            word_count[test_word] += 1\n",
    "            audio_chunk.export(join(exp_folder, test_word + \"_{num:02d}.wav\".format(num=word_count[test_word])), format='wav')\n",
    "        else: # the phrase/sent files\n",
    "            audio_chunk.export(join(exp_folder, exp_name + \"_{num:02d}.wav\".format(num=idx+1)), format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER: gla_001/female/joh001\n"
     ]
    }
   ],
   "source": [
    "for speaker in speakers:\n",
    "    print(\"SPEAKER: \" + speaker)\n",
    "    abs_path_spk = join(DATA_ROOT, speaker)\n",
    "    for file in listdir(abs_path_spk):\n",
    "    # only examines text files (timestamp files) since they correspond to the audio files\n",
    "        if file.endswith(\".txt\"): \n",
    "            split_audio(abs_path_spk, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find total average audio length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the total average audio length for the ARCTIC-L2 set to decide what audio files for ABI.\n",
    "Best to use cwa-cwe (the single word files) for training, plus some short passages/phrases.\n",
    "However, the porportion of short passages/phrases used for testing needs to be decided as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2-ARCTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mBDL\u001b[m\u001b[m  \u001b[34mCLB\u001b[m\u001b[m  \u001b[34mEBVS\u001b[m\u001b[m \u001b[34mHKK\u001b[m\u001b[m  \u001b[34mNJS\u001b[m\u001b[m  \u001b[34mRRBI\u001b[m\u001b[m \u001b[34mTNI\u001b[m\u001b[m  \u001b[34mYDCK\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import join, expanduser, exists, basename\n",
    "DATA_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/data\", \"arctic2\")\n",
    "!ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of total audio duration with (train, test) pairs per speaker\n",
    "# to find the average length of the train and test folders separately\n",
    "total_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the total duration of audio (train + test) per speaker\n",
    "for idx, speaker in enumerate(listdir(DATA_ROOT)):\n",
    "    if speaker == \".DS_Store\":\n",
    "        continue\n",
    "    train_dir, test_dir = join(DATA_ROOT, speaker, 'train'), join(DATA_ROOT, speaker, 'test')\n",
    "    train_sum, test_sum = sum([librosa.get_duration(filename= join(train_dir,f)) for f in listdir(train_dir) if f != '.DS_Store']), \\\n",
    "                          sum([librosa.get_duration(filename= join(test_dir,f)) for f in listdir(test_dir) if f != '.DS_Store'])\n",
    "    total_durations.append((train_sum, test_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(422.3204308390022, 214.28770975056696),\n",
       " (365.801224489796, 174.99764172335605),\n",
       " (395.8359410430841, 195.9173242630385),\n",
       " (379.4438775510204, 186.1926984126984),\n",
       " (328.9279818594104, 164.5161224489796),\n",
       " (325.0589342403629, 160.16165532879813),\n",
       " (277.08481250000006, 142.44237499999997),\n",
       " (348.7399999999999, 173.86999999999998)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total = 0\n",
    "test_total = 0\n",
    "for sum_pair in total_durations:\n",
    "    train_total += sum_pair[0]\n",
    "    test_total += sum_pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AVERAGES: 355.4016503153345\n",
      "TEST AVERAGES: 176.5481908659297\n",
      "TOTAL AVERAGE: 531.9498411812642\n"
     ]
    }
   ],
   "source": [
    "train_avg = train_total / len(total_durations)\n",
    "test_avg = test_total / len(total_durations) \n",
    "\n",
    "print('TRAINING AVERAGES: ' + str(train_avg))\n",
    "print('TEST AVERAGES: ' + str(test_avg))\n",
    "print('TOTAL AVERAGE: ' + str((train_avg + test_avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AVERAGES: 05:55\n",
      "TEST AVERAGES: 02:56\n",
      "TOTAL AVERAGE: 08:51\n"
     ]
    }
   ],
   "source": [
    "train_avg = train_total / len(total_durations)\n",
    "test_avg = test_total / len(total_durations) \n",
    "\n",
    "print('TRAINING AVERAGES: ' + '%02d:%02d'%(divmod(train_avg, 60)))\n",
    "print('TEST AVERAGES: ' + '%02d:%02d'%(divmod(test_avg, 60)))\n",
    "print('TOTAL AVERAGE: ' + '%02d:%02d'%(divmod(train_avg + test_avg, 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mbrm_001\u001b[m\u001b[m \u001b[34mean_001\u001b[m\u001b[m \u001b[34mgla_001\u001b[m\u001b[m \u001b[34mlan_001\u001b[m\u001b[m \u001b[34mncl_001\u001b[m\u001b[m \u001b[34mroi_001\u001b[m\u001b[m \u001b[34msse_001\u001b[m\u001b[m\n",
      "\u001b[34mcrn_001\u001b[m\u001b[m \u001b[34meyk_001\u001b[m\u001b[m \u001b[34milo_001\u001b[m\u001b[m \u001b[34mlvp_001\u001b[m\u001b[m \u001b[34mnwa_001\u001b[m\u001b[m \u001b[34mshl_001\u001b[m\u001b[m \u001b[34muls_001\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import join, expanduser, exists, basename\n",
    "DATA_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/data\", \"ABI-1\")\n",
    "!ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of speakers in ABI corpus in 'accent/gender/speaker' format\n",
    "speakers = ['gla_001/male/sgd001', 'gla_001/female/lxd001', 'sse_001/male/prz001', 'sse_001/female/wjh001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of total audio duration per speaker\n",
    "total_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the total duration of audio (train + test) per speaker\n",
    "for idx, speaker in enumerate(speakers):\n",
    "    abs_path = join(DATA_ROOT, speaker)\n",
    "    speaker_sum = sum([librosa.get_duration(filename=join(abs_path,f)) for f in listdir(abs_path) if (f != '.DS_Store' and f.endswith('.wav'))])\n",
    "    total_durations.append(speaker_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[312.2216780045352, 288.4738321995465, 383.71519274376413, 358.0925170068028]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL AVERAGE: 05:35\n"
     ]
    }
   ],
   "source": [
    "total_avg = sum(total_durations) / len(total_durations)\n",
    "minutes, seconds = divmod(total_avg, 60)\n",
    "print('TOTAL AVERAGE: ' + '%02d:%02d'%(minutes,seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length should be roughly: 03:43\n",
      "Test set length should be roughly: 01:51\n"
     ]
    }
   ],
   "source": [
    "train_len = total_avg * 2 / 3\n",
    "test_len = total_avg * 1 / 3\n",
    "train_minutes, train_seconds = divmod(train_len, 60)\n",
    "test_minutes, test_seconds = divmod(test_len, 60) \n",
    "print('Train set length should be roughly: ' + '%02d:%02d'%(train_minutes,train_seconds))\n",
    "print('Test set length should be roughly: ' + '%02d:%02d'%(test_minutes,test_seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided to use shortphrases + shortsentences as test set as they add up roughly ot 01:51 on average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select test audios and organizes them into individual folders per evaluation criteria for each speaker. \n",
    "Also renames the audio files for easier viewing by the evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import choice, shuffle\n",
    "from random import randint\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, expanduser, exists, basename, isdir, splitext, abspath, split\n",
    "from shutil import copyfile\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mbrm_001\u001b[m\u001b[m \u001b[34mean_001\u001b[m\u001b[m \u001b[34mgla_001\u001b[m\u001b[m \u001b[34mlan_001\u001b[m\u001b[m \u001b[34mncl_001\u001b[m\u001b[m \u001b[34mroi_001\u001b[m\u001b[m \u001b[34msse_001\u001b[m\u001b[m\n",
      "\u001b[34mcrn_001\u001b[m\u001b[m \u001b[34meyk_001\u001b[m\u001b[m \u001b[34milo_001\u001b[m\u001b[m \u001b[34mlvp_001\u001b[m\u001b[m \u001b[34mnwa_001\u001b[m\u001b[m \u001b[34mshl_001\u001b[m\u001b[m \u001b[34muls_001\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/data/\", \"ABI-1\")\n",
    "!ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eastanglia-EAN-htl001-128.ipynb \u001b[34mtest_PA\u001b[m\u001b[m\n",
      "\u001b[34moutput\u001b[m\u001b[m                          \u001b[34mtest_SI\u001b[m\u001b[m\n",
      "\u001b[34mtest_AQ\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "EXP_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/experiments\", \"abi\")\n",
    "!ls $EXP_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_speakers = ['gla_001/male/wht001', 'gla_001/female/joh001', \n",
    "                'lan_001/male/gxi002', 'lan_001/female/jxd001',\n",
    "                'ean_001/male/htl001', 'ean_001/female/nxp001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General methods for selecting random audios and their original src and tgt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a speaker directory from the 'experiments' folder to select \n",
    "# 10 random AC files to use in evaluation;\n",
    "# returns the gender, accent and randomly chosen AC files\n",
    "def select_rand_audios(speaker_dir):\n",
    "    # removes the non-MLPG and hidden files; selects the 'output' folder\n",
    "    AC_files = list(filter(lambda x: not x.startswith('.') and x.endswith('w_MLPG.wav'), listdir(join(speaker_dir, 'output'))))\n",
    "    AC_files = [join(speaker_dir, 'output', f) for f in AC_files]\n",
    "    rand_AC_files = choice(AC_files, 10, replace=False)\n",
    "    return rand_AC_files # d = gender, s = accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the chosen gender/accent of a speaker and its randomly chosen files\n",
    "# to find and returns a list with original source audio\n",
    "# and a list with original target audio used in conversion\n",
    "\n",
    "def get_matching_audio(gender, accent, rand_AC_files):\n",
    "    src_path = '' # path to source audio folder\n",
    "    \n",
    "    if gender == 'male':\n",
    "        src_path = join(DATA_ROOT, 'sse_001/male/rkm001')\n",
    "    elif gender == 'female':\n",
    "        src_path = join(DATA_ROOT, 'sse_001/female/wjh001')\n",
    "    \n",
    "    # find the target path since ABI contains extra speakers\n",
    "    tgt_path = '' # speaker data path; e.g. ../male/GLA\n",
    "    for s in exp_speakers:\n",
    "        accent_path, gender_path = s.split('/')[0], s.split('/')[1]\n",
    "        if accent_path.startswith(accent.lower()) and gender_path == gender:\n",
    "            tgt_path = join(DATA_ROOT, s)\n",
    "            break\n",
    "    \n",
    "    orig_src_audio = []\n",
    "    orig_tgt_audio = []\n",
    "    for AC_file in rand_AC_files:\n",
    "        path, AC_file = split(AC_file)\n",
    "        AC_file = AC_file.replace('AC-w_MLPG.wav', '') # removes extra AC extension to find matching original audio\n",
    "        exp_type = AC_file.split('_')[0]  # shortphrases or shortsentences\n",
    "        \n",
    "        exp_src_folder = join(src_path, exp_type)\n",
    "        for orig_src_file in listdir(exp_src_folder):\n",
    "            if AC_file in orig_src_file: # if AC file name matches src file\n",
    "                full_audio_path = join(exp_src_folder, orig_src_file)\n",
    "                orig_src_audio.append(full_audio_path)\n",
    "        \n",
    "        exp_tgt_folder = join(tgt_path, exp_type)\n",
    "        for orig_tgt_file in listdir(exp_tgt_folder):\n",
    "            if AC_file in orig_tgt_file: # if AC file name matches tgt file\n",
    "                full_audio_path = join(exp_tgt_folder, orig_tgt_file)\n",
    "                orig_tgt_audio.append(full_audio_path)\n",
    "    \n",
    "    return orig_src_audio, orig_tgt_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acoustic Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the gender, accent, and randomly chosen AC files to copy/move and \n",
    "# rename each file to a folder 'test_AQ' for easier viewing; \n",
    "# outputs the original filenames in a separate text file\n",
    "\n",
    "def create_test_AQ(gender, accent, rand_AC_files):\n",
    "    test_AQ_path = join(EXP_ROOT, gender, accent, 'test_AQ')\n",
    "    if not exists(test_AQ_path):\n",
    "        makedirs(test_AQ_path)\n",
    "\n",
    "    file_prefix = accent + '_' + gender # Ex. EAN_male\n",
    "    \n",
    "    with open(join(test_AQ_path, (file_prefix + '_test_AQ.txt')), 'w') as f:\n",
    "        for idx, file in enumerate(rand_AC_files):\n",
    "              f.write(file + '\\n') # write original name to txt file\n",
    "              renamed = file_prefix + '_test_AQ_' + str(idx + 1) + '.wav' # Ex. EAN_male_test_AQ_1.wav\n",
    "              copyfile(file, join(test_AQ_path, renamed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percieved Accentedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the gender, accent, and randomly chosen AC files to copy/move and \n",
    "# rename each file to a folder 'test_AQ' for easier viewing; \n",
    "# outputs the original filenames in a separate text file\n",
    "\n",
    "def create_test_PA(gender, accent, orig_src, orig_tgt, rand_AC_files):\n",
    "    test_PA_path = join(EXP_ROOT, gender, accent, 'test_PA')\n",
    "    if not exists(test_PA_path):\n",
    "        makedirs(test_PA_path)\n",
    "\n",
    "    file_prefix = accent + '_' + gender # Ex. EAN_male\n",
    "    \n",
    "    with open(join(test_PA_path, (file_prefix + '_test_PA.txt')), 'w') as f:\n",
    "        for idx, file in enumerate(rand_AC_files):\n",
    "            renamed_A = file_prefix + '_test_PA_' + str(idx + 1) + 'A' + '.wav'\n",
    "            renamed_B = file_prefix + '_test_PA_' + str(idx + 1) + 'B' + '.wav'\n",
    "            renamed_X = file_prefix + '_test_PA_' + str(idx + 1) + 'X' + '.wav' # AC_file\n",
    "            \n",
    "            orig_audio_pair = [orig_src[idx], orig_tgt[idx]] # matching src and tgt audio\n",
    "            shuffle(orig_audio_pair)\n",
    "            \n",
    "            f.write(orig_audio_pair[0] + '\\n') # write original name for A to txt file\n",
    "            f.write(orig_audio_pair[1] + '\\n') # write original name for B to txt file\n",
    "            f.write(file + '\\n\\n') # write original name for X to txt file\n",
    "            \n",
    "            copyfile(orig_audio_pair[0], join(test_PA_path, renamed_A))\n",
    "            copyfile(orig_audio_pair[1], join(test_PA_path, renamed_B))\n",
    "            copyfile(file, join(test_PA_path, renamed_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the gender, accent, and randomly chosen AC files to copy/move and \n",
    "# rename each file to a folder 'test_AQ' for easier viewing; \n",
    "# outputs the original filenames in a separate text file\n",
    "\n",
    "def create_test_SI(gender, accent, orig_src, orig_tgt, rand_AC_files):\n",
    "    test_SI_path = join(EXP_ROOT, gender, accent, 'test_SI')\n",
    "    if not exists(test_SI_path):\n",
    "        makedirs(test_SI_path)\n",
    "\n",
    "    file_prefix = accent + '_' + gender # Ex. EAN_male\n",
    "    \n",
    "    src_counter, tgt_counter = 0, 0\n",
    "    \n",
    "    with open(join(test_SI_path, (file_prefix + '_test_SI.txt')), 'w') as f:\n",
    "        for idx, file in enumerate(rand_AC_files):\n",
    "            renamed_A = file_prefix + '_test_SI_' + str(idx + 1) + 'A' + '.wav'\n",
    "            renamed_B = file_prefix + '_test_SI_' + str(idx + 1) + 'B' + '.wav'\n",
    "            \n",
    "            orig_audio_pair = [orig_src[idx], orig_tgt[idx]] # matching src and tgt audio\n",
    "            \n",
    "            rnd = randint(0, 1) # select src/tgt randomly\n",
    "            \n",
    "            if src_counter >= 5:\n",
    "                rnd = 1\n",
    "            elif tgt_counter >= 5:\n",
    "                rnd = 0\n",
    "            \n",
    "            if rnd == 0:\n",
    "                src_counter += 1\n",
    "            else:\n",
    "                tgt_counter += 1\n",
    "\n",
    "            test_pair = [orig_audio_pair[rnd], file] # pair selected src/tgt file and AC file\n",
    "            shuffle(test_pair)\n",
    "            \n",
    "            f.write(test_pair[0] + '\\n') # write original name for A to txt file\n",
    "            f.write(test_pair[1] + '\\n\\n') # write original name for B to txt file\n",
    "            \n",
    "            rate_A, audio_A = wavfile.read(test_pair[0])\n",
    "            rate_B, audio_B = wavfile.read(test_pair[1])\n",
    "            \n",
    "            backwards_A = audio_A[::-1] # reverses audio\n",
    "            backwards_B = audio_B[::-1]\n",
    "            \n",
    "            wavfile.write(join(test_SI_path, renamed_A), rate_A, backwards_A)\n",
    "            wavfile.write(join(test_SI_path, renamed_B), rate_B, backwards_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLA\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'shortphrases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-09bd2f65fc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mspeaker_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mrand_AC_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_rand_audios\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0morig_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matching_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_AC_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mcreate_test_AQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_AC_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# d = gender, s = speaker/accent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mcreate_test_PA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_tgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_AC_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-93b1a03f79bf>\u001b[0m in \u001b[0;36mget_matching_audio\u001b[0;34m(gender, accent, rand_AC_files)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mexp_tgt_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0morig_tgt_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_tgt_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mAC_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morig_tgt_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if AC file name matches tgt file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mfull_audio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_tgt_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_tgt_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'shortphrases'"
     ]
    }
   ],
   "source": [
    "# goes through each speaker used in the experiment to generate the Acoustic Quality test set\n",
    "for d in listdir(EXP_ROOT):\n",
    "        if not d.startswith('.'):\n",
    "            gender_dirs = join(EXP_ROOT, d)\n",
    "            speakers = list(filter(lambda x: not x.startswith('.'), listdir(gender_dirs))) # removes hidden files and gives list of speakers\n",
    "            for s in speakers:\n",
    "                speaker_dir = join(gender_dirs, s)\n",
    "                rand_AC_files = select_rand_audios(speaker_dir)\n",
    "                orig_src, orig_tgt = get_matching_audio(d, s, rand_AC_files)\n",
    "                create_test_AQ(d, s, rand_AC_files) # d = gender, s = speaker/accent\n",
    "                create_test_PA(d, s, orig_src, orig_tgt, rand_AC_files)\n",
    "                create_test_SI(d, s, orig_src, orig_tgt, rand_AC_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mBDL\u001b[m\u001b[m  \u001b[34mCLB\u001b[m\u001b[m  \u001b[34mEBVS\u001b[m\u001b[m \u001b[34mHKK\u001b[m\u001b[m  \u001b[34mNJS\u001b[m\u001b[m  \u001b[34mRRBI\u001b[m\u001b[m \u001b[34mTNI\u001b[m\u001b[m  \u001b[34mYDCK\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/data\", \"arctic2\")\n",
    "!ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfemale\u001b[m\u001b[m \u001b[34mmale\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "EXP_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/experiments\", \"arctic\")\n",
    "!ls $EXP_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a speaker directory from the 'experiments' folder to select \n",
    "# 10 random AC files to use in evaluation;\n",
    "# returns the gender, accent and randomly chosen AC files\n",
    "def select_rand_audios(speaker_dir):\n",
    "    # removes the non-MLPG and hidden files; selects the 'output' folder\n",
    "    AC_files = list(filter(lambda x: not x.startswith('.') and x.endswith('w_MLPG.wav'), listdir(join(speaker_dir, 'output'))))\n",
    "    AC_files = [join(speaker_dir, 'output', f) for f in AC_files]\n",
    "    rand_AC_files = choice(AC_files, 10, replace=False)\n",
    "    return rand_AC_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the chosen gender/accent of a speaker and its randomly chosen files\n",
    "# to find and returns a list with original source audio\n",
    "# and a list with original target audio used in conversion\n",
    "\n",
    "def get_matching_audio(gender, rand_AC_files):\n",
    "    src_path = '' # path to source audio folder\n",
    "\n",
    "    if gender == 'male':\n",
    "        src_path = join(DATA_ROOT, 'BDL', 'wav')\n",
    "    elif gender == 'female':\n",
    "        src_path = join(DATA_ROOT, 'CLB', 'wav')\n",
    "        \n",
    "    speaker_ID = ''\n",
    "    for speaker in listdir(DATA_ROOT):\n",
    "        ID_temp = basename(rand_AC_files[0])[:3] # temporary speaker ID; matches some len(3) ids, but some speakers have len(4) ids\n",
    "        if ID_temp in speaker:\n",
    "            speaker_ID = speaker\n",
    "            \n",
    "    tgt_path = join(DATA_ROOT, speaker_ID, 'wav') # path to target audio folder; e.g. HKK/wav\n",
    "    \n",
    "    orig_src_audio = []\n",
    "    orig_tgt_audio = []\n",
    "    for AC_file in rand_AC_files:\n",
    "        path, AC_file = split(AC_file)\n",
    "        AC_file = AC_file.replace('AC-w_MLPG.wav', '') # removes extra AC extension to find matching original audio\n",
    "        AC_file = AC_file.replace(speaker_ID, '', 1) # removes the speaker ID from the file name\n",
    "        \n",
    "        for orig_src_file in listdir(src_path):\n",
    "            if AC_file in orig_src_file: # if AC file name matches src file\n",
    "                full_audio_path = join(src_path, orig_src_file)\n",
    "                orig_src_audio.append(full_audio_path)\n",
    "                \n",
    "        for orig_tgt_file in listdir(tgt_path):\n",
    "            if AC_file in orig_tgt_file: # if AC file name matches tgt file\n",
    "                full_audio_path = join(tgt_path, orig_tgt_file)\n",
    "                orig_tgt_audio.append(full_audio_path)\n",
    "    \n",
    "    return orig_src_audio, orig_tgt_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acoustic Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the gender, accent, and randomly chosen AC files to copy/move and \n",
    "# rename each file to a folder 'test_AQ' for easier viewing; \n",
    "# outputs the original filenames in a separate text file\n",
    "\n",
    "def create_test_AQ(gender, accent, rand_AC_files):\n",
    "    test_AQ_path = join(EXP_ROOT, gender, accent, 'test_AQ')\n",
    "    if not exists(test_AQ_path):\n",
    "        makedirs(test_AQ_path)\n",
    "\n",
    "    file_prefix = accent + '_' + gender # Ex. EAN_male\n",
    "    \n",
    "    with open(join(test_AQ_path, (file_prefix + '_test_AQ.txt')), 'w') as f:\n",
    "        for idx, file in enumerate(rand_AC_files):\n",
    "            f.write(file + '\\n') # write original name to txt file\n",
    "            renamed = file_prefix + '_test_AQ_' + str(idx + 1) + '.wav' # Ex. EAN_male_test_AQ_1.wav\n",
    "            copyfile(file, join(test_AQ_path, renamed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percieved Accentedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the gender, accent, and randomly chosen AC files to copy/move and \n",
    "# rename each file to a folder 'test_AQ' for easier viewing; \n",
    "# outputs the original filenames in a separate text file\n",
    "\n",
    "def create_test_PA(gender, accent, orig_src, orig_tgt, rand_AC_files):\n",
    "    test_PA_path = join(EXP_ROOT, gender, accent, 'test_PA')\n",
    "    if not exists(test_PA_path):\n",
    "        makedirs(test_PA_path)\n",
    "\n",
    "    file_prefix = accent + '_' + gender # Ex. EAN_male\n",
    "    \n",
    "    with open(join(test_PA_path, (file_prefix + '_test_PA.txt')), 'w') as f:\n",
    "        for idx, file in enumerate(rand_AC_files):\n",
    "            renamed_A = file_prefix + '_test_PA_' + str(idx + 1) + 'A' + '.wav'\n",
    "            renamed_B = file_prefix + '_test_PA_' + str(idx + 1) + 'B' + '.wav'\n",
    "            renamed_X = file_prefix + '_test_PA_' + str(idx + 1) + 'X' + '.wav' # AC_file\n",
    "            \n",
    "            orig_audio_pair = [orig_src[idx], orig_tgt[idx]] # matching src and tgt audio\n",
    "            shuffle(orig_audio_pair)\n",
    "            \n",
    "            f.write(orig_audio_pair[0] + '\\n') # write original name for A to txt file\n",
    "            f.write(orig_audio_pair[1] + '\\n') # write original name for B to txt file\n",
    "            f.write(file + '\\n\\n') # write original name for X to txt file\n",
    "            \n",
    "            copyfile(orig_audio_pair[0], join(test_PA_path, renamed_A))\n",
    "            copyfile(orig_audio_pair[1], join(test_PA_path, renamed_B))\n",
    "            copyfile(file, join(test_PA_path, renamed_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the gender, accent, and randomly chosen AC files to copy/move and \n",
    "# rename each file to a folder 'test_AQ' for easier viewing; \n",
    "# outputs the original filenames in a separate text file\n",
    "\n",
    "def create_test_SI(gender, accent, orig_src, orig_tgt, rand_AC_files):\n",
    "    test_SI_path = join(EXP_ROOT, gender, accent, 'test_SI')\n",
    "    if not exists(test_SI_path):\n",
    "        makedirs(test_SI_path)\n",
    "\n",
    "    file_prefix = accent + '_' + gender # Ex. EAN_male\n",
    "    \n",
    "    src_counter, tgt_counter = 0, 0\n",
    "    \n",
    "    with open(join(test_SI_path, (file_prefix + '_test_SI.txt')), 'w') as f:\n",
    "        for idx, file in enumerate(rand_AC_files):\n",
    "            renamed_A = file_prefix + '_test_SI_' + str(idx + 1) + 'A' + '.wav'\n",
    "            renamed_B = file_prefix + '_test_SI_' + str(idx + 1) + 'B' + '.wav'\n",
    "            \n",
    "            orig_audio_pair = [orig_src[idx], orig_tgt[idx]] # matching src and tgt audio\n",
    "            \n",
    "            rnd = randint(0, 1) # select src/tgt randomly\n",
    "            \n",
    "            if src_counter >= 5:\n",
    "                rnd = 1\n",
    "            elif tgt_counter >= 5:\n",
    "                rnd = 0\n",
    "            \n",
    "            if rnd == 0:\n",
    "                src_counter += 1\n",
    "            else:\n",
    "                tgt_counter += 1\n",
    "\n",
    "            test_pair = [orig_audio_pair[rnd], file] # pair selected src/tgt file and AC file\n",
    "            shuffle(test_pair)\n",
    "            \n",
    "            f.write(test_pair[0] + '\\n') # write original name for A to txt file\n",
    "            f.write(test_pair[1] + '\\n\\n') # write original name for B to txt file\n",
    "            \n",
    "            rate_A, audio_A = wavfile.read(test_pair[0])\n",
    "            rate_B, audio_B = wavfile.read(test_pair[1])\n",
    "            \n",
    "            backwards_A = audio_A[::-1] # reverses audio\n",
    "            backwards_B = audio_B[::-1]\n",
    "            \n",
    "            wavfile.write(join(test_SI_path, renamed_A), rate_A, backwards_A)\n",
    "            wavfile.write(join(test_SI_path, renamed_B), rate_B, backwards_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through each speaker used in the experiment to generate the Acoustic Quality test set\n",
    "for d in listdir(EXP_ROOT):\n",
    "        if not d.startswith('.'):\n",
    "            gender_dirs = join(EXP_ROOT, d)\n",
    "            speakers = list(filter(lambda x: not x.startswith('.'), listdir(gender_dirs))) # removes hidden files and gives list of speakers\n",
    "            for s in speakers:\n",
    "                speaker_dir = join(gender_dirs, s)\n",
    "                rand_AC_files = select_rand_audios(speaker_dir)\n",
    "                orig_src, orig_tgt = get_matching_audio(d, rand_AC_files) # d = gender\n",
    "                create_test_AQ(d, s, rand_AC_files) \n",
    "                create_test_PA(d, s, orig_src, orig_tgt, rand_AC_files)\n",
    "                create_test_SI(d, s, orig_src, orig_tgt, rand_AC_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
