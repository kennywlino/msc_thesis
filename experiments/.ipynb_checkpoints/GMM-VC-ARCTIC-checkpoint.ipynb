{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice conversion prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with GMMs; Arctic corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speakers p299 and p248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcmu_us_awb_arctic\u001b[m\u001b[m \u001b[34mcmu_us_clb_arctic\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# open data\n",
    "from os.path import join, expanduser\n",
    "DATA_ROOT = join(expanduser(\"~\"), \"Documents/em_lct/UoM/thesis/data/\", \"arctic\")\n",
    "!ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# nnmnkwii imports taken from example notebook on VC\n",
    "%pylab inline\n",
    "rcParams[\"figure.figsize\"] = (16,5)\n",
    "\n",
    "from nnmnkwii.datasets import PaddedFileSourceDataset\n",
    "from nnmnkwii.datasets.cmu_arctic import CMUArcticWavFileDataSource\n",
    "from nnmnkwii.preprocessing.alignment import DTWAligner\n",
    "from nnmnkwii.preprocessing import trim_zeros_frames, remove_zeros_frames, delta_features\n",
    "from nnmnkwii.util import apply_each2d_trim\n",
    "from nnmnkwii.metrics import melcd\n",
    "from nnmnkwii.baseline.gmm import MLPG\n",
    "\n",
    "from os import listdir\n",
    "from os.path import basename, splitext, join, splitext, isdir\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import pyworld\n",
    "import pysptk\n",
    "from pysptk.synthesis import MLSADF, Synthesizer\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "fftlen = pyworld.get_cheaptrick_fft_size(fs)\n",
    "alpha = pysptk.util.mcepalpha(fs)\n",
    "order = 24\n",
    "frame_period = 5\n",
    "hop_length = int(fs * (frame_period * 0.001))\n",
    "max_files = 150 # number of utterances to be used.\n",
    "test_size = 0.33\n",
    "use_delta = True\n",
    "\n",
    "if use_delta:\n",
    "    windows = [\n",
    "        (0, 0, np.array([1.0])),\n",
    "        (1, 1, np.array([-0.5, 0.0, 0.5])),\n",
    "        (1, 1, np.array([1.0, -2.0, 1.0])),\n",
    "    ]\n",
    "else:\n",
    "    windows = [\n",
    "        (0, 0, np.array([1.0])),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFileDataSource(CMUArcticWavFileDataSource):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyFileDataSource, self).__init__(*args, **kwargs)\n",
    "        self.test_paths = None\n",
    "\n",
    "    def collect_files(self):\n",
    "        paths = super(\n",
    "            MyFileDataSource, self).collect_files()\n",
    "        paths_train, paths_test = train_test_split(\n",
    "            paths, test_size=test_size, random_state=42)\n",
    "\n",
    "        # keep paths for later testing\n",
    "        self.test_paths = paths_test\n",
    "\n",
    "        return paths_train\n",
    "\n",
    "    def collect_features(self, path):\n",
    "        x, frame_sample = librosa.load(path, sr=fs, dtype=float64)\n",
    "        f0, timeaxis = pyworld.dio(x, frame_sample, frame_period=frame_period)\n",
    "        f0 = pyworld.stonemask(x, f0, timeaxis, frame_sample)\n",
    "        spectrogram = pyworld.cheaptrick(x, f0, timeaxis, frame_sample)\n",
    "        spectrogram = trim_zeros_frames(spectrogram)\n",
    "        mc = pysptk.sp2mc(spectrogram, order=order, alpha=alpha)\n",
    "        return mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_speaker = MyFileDataSource(data_root=DATA_ROOT, speakers=[\"awb\"], max_files=max_files) # This is actually speaker TNI from Arctic L2\n",
    "tgt_speaker = MyFileDataSource(data_root=DATA_ROOT, speakers=[\"clb\"], max_files=max_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 1200, 25)\n",
      "(67, 1200, 25)\n"
     ]
    }
   ],
   "source": [
    "# convert training sets into arrays\n",
    "X = PaddedFileSourceDataset(src_speaker, 1200).asarray()\n",
    "Y = PaddedFileSourceDataset(tgt_speaker, 1200).asarray()\n",
    "print(X.shape)\n",
    "print(Y.shape) \n",
    "# shape = (13 training audios, 2800 frames, 25 features per frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0084.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0054.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0071.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0046.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0045.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0040.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0023.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0081.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0011.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0001.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0019.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0031.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0074.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0034.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0091.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0005.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0077.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0078.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0013.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0032.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0056.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0089.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0027.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0043.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0070.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0016.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0041.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0097.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0010.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0073.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0012.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0048.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_awb_arctic/wav/arctic_a0086.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_speaker.test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0084.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0054.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0071.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0046.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0045.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0040.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0023.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0081.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0011.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0001.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0019.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0031.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0074.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0034.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0091.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0005.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0077.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0078.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0013.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0032.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0056.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0089.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0027.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0043.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0070.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0016.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0041.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0097.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0010.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0073.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0012.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0048.wav',\n",
       " '/Users/kennylino/Documents/em_lct/UoM/thesis/data/arctic/cmu_us_clb_arctic/wav/arctic_a0086.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_speaker.test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting util\n",
    "def plot_parallel(x,y):\n",
    "    figure(figsize=(16,7))\n",
    "    subplot(2,1,1)\n",
    "    librosa.display.specshow(trim_zeros_frames(x).T, sr=fs, hop_length=hop_length, x_axis=\"time\")\n",
    "    colorbar()\n",
    "    subplot(2,1,2)\n",
    "    librosa.display.specshow(trim_zeros_frames(y).T, sr=fs, hop_length=hop_length, x_axis=\"time\")\n",
    "    colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5bb6656489f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;31m# any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-36dc2b399d71>\u001b[0m in \u001b[0;36mplot_parallel\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrim_zeros_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frame_sample' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 6 # any \n",
    "plot_parallel(X[idx],Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment\n",
    "X_aligned, Y_aligned = DTWAligner(verbose=0, dist=melcd).transform((X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel(X_aligned[idx],Y_aligned[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 1st (power) dimension\n",
    "X_aligned, Y_aligned = X_aligned[:, :, 1:], Y_aligned[:, :, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_dim = X_aligned.shape[-1]\n",
    "if use_delta:\n",
    "    X_aligned = apply_each2d_trim(delta_features, X_aligned, windows)\n",
    "    Y_aligned = apply_each2d_trim(delta_features, Y_aligned, windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel(X_aligned[idx],Y_aligned[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans clustering of MFCC feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_X = KMeans(n_clusters=512, init='k-means++', max_iter=100, n_init=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aligned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenates all of the frames in each sentence since k-means needs one large vector\n",
    "all_frames_X = numpy.concatenate(X_aligned, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should equal number of frames * number of utterances\n",
    "len(all_frames_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 frames are removed since they are all exactly the same\n",
    "all_frames_X = remove_zeros_frames(all_frames_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_frames_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "km_X.fit(all_frames_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help taken from: https://stackoverflow.com/questions/36195457/python-sklearn-kmeans-how-to-get-the-values-in-the-cluster\n",
    "clustered_X = pd.DataFrame()\n",
    "clustered_X['frame'] = all_frames_X.tolist()\n",
    "clustered_X['cluster #'] = km_X.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dist_X = clustered_X.groupby('cluster #').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use print(cluster_dist_X.to_string()) to see whole dist\n",
    "print (cluster_dist_X.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dist_X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering of the target speaker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_Y = KMeans(n_clusters=512, init='k-means++', max_iter=100, n_init=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenates all of the frames in each sentence since k-means needs one large vector\n",
    "all_frames_Y = numpy.concatenate(Y_aligned, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should equal number of frames * number of utterances\n",
    "len(all_frames_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_frames_Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 frames are removed since they are all exactly the same\n",
    "all_frames_Y = remove_zeros_frames(all_frames_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "km_Y.fit(all_frames_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help taken from: https://stackoverflow.com/questions/36195457/python-sklearn-kmeans-how-to-get-the-values-in-the-cluster\n",
    "clustered_Y = pd.DataFrame()\n",
    "clustered_Y['frame'] = all_frames_Y.tolist()\n",
    "clustered_Y['cluster #'] = km_Y.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dist_Y = clustered_Y.groupby('cluster #').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use print(cluster_dist_Y.to_string()) to see whole dist\n",
    "print (cluster_dist_Y.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dist_Y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the look-up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# shape = (13 training audios, 2800 frames, 25 features per frame)\n",
    "# if using array as key doesn't work, use the string representation\n",
    "# and convert the array into a string when looking it up in the dictionary\n",
    "\n",
    "\n",
    "# all_frames_x contains each frame from each audio inside of X (aka X_aligned)\n",
    "\n",
    "# the psuedocode for finding closest frames \n",
    "# for frame in all_frames_X:\n",
    "#    predict the cluster of the frame in clustered_Y\n",
    "#    find the closest data point in clustered_Y to frame\n",
    "#    store X_frame and most similar frame, Y_frame in paired_frames_X\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "# bytes version of X: array from Y\n",
    "paired_frames_X = {}\n",
    "\n",
    "for frame in all_frames_X:\n",
    "    # needs to be reshaped to shape of km training data \n",
    "    frame_pred = frame.reshape(1, -1)\n",
    "    predicted_cluster = km_Y.predict(frame_pred)[0] # returns cluster num\n",
    "    # grabs the possible frames and converts them to the proper array format for KDTree\n",
    "    possible_frames = (clustered_Y[clustered_Y['cluster #'] == predicted_cluster]['frame'].values).tolist()\n",
    "    tree = spatial.KDTree(possible_frames)\n",
    "    # tree.query() returns (the distance between the closest frame and index in series)\n",
    "    most_similar = tree.query(frame)\n",
    "    most_similar_vec = np.array(possible_frames[most_similar[1]]) # index in possible_frames\n",
    "    frame_key = frame.tobytes() # converted to bytes since arrays cannot be keys\n",
    "    paired_frames_X[frame_key] = most_similar_vec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the 'most similar to X' array\n",
    "Y = np.array([paired_frames_X[frame.tobytes()] for frame in all_frames_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = np.concatenate((all_frames_X, Y), axis=-1)\n",
    "print(XY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(\n",
    "    n_components=64, covariance_type=\"full\", max_iter=100, verbose=1)\n",
    "\n",
    "%time gmm.fit(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    plot(gmm.means_[k], linewidth=1.5, label=\"Mean of mixture {}\".format(k+1))\n",
    "legend(prop={\"size\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(gmm.covariances_[0], origin=\"bottom left\")\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    plot(np.diag(gmm.covariances_[k]), linewidth=1.5, \n",
    "         label=\"Diagonal part of covariance matrix, mixture {}\".format(k))\n",
    "legend(prop={\"size\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_utt(src_path, tgt_path, disable_mlpg=False, diffvc=True):\n",
    "    # GMM-based parameter generation is provided by the library in `baseline` module\n",
    "    if disable_mlpg:\n",
    "        # Force disable MLPG\n",
    "        paramgen = MLPG(gmm, windows=[(0,0, np.array([1.0]))], diff=diffvc)\n",
    "    else:\n",
    "        paramgen = MLPG(gmm, windows=windows, diff=diffvc)\n",
    "\n",
    "    x, frame_sample = librosa.load(src_path, sr=fs, dtype=float64)\n",
    "    f0, timeaxis = pyworld.dio(x, frame_sample, frame_period=frame_period)\n",
    "    f0 = pyworld.stonemask(x, f0, timeaxis, frame_sample)\n",
    "    spectrogram = pyworld.cheaptrick(x, f0, timeaxis, frame_sample)\n",
    "    aperiodicity = pyworld.d4c(x, f0, timeaxis, frame_sample)\n",
    "\n",
    "    mc = pysptk.sp2mc(spectrogram, order=order, alpha=alpha)\n",
    "    c0, mc = mc[:, 0], mc[:, 1:]\n",
    "    if use_delta:\n",
    "        mc = delta_features(mc, windows)\n",
    "    mc = paramgen.transform(mc)\n",
    "    if disable_mlpg and mc.shape[-1] != static_dim:\n",
    "        mc = mc[:,:static_dim]\n",
    "    assert mc.shape[-1] == static_dim\n",
    "    mc = np.hstack((c0[:, None], mc))\n",
    "    if diffvc:\n",
    "        mc[:, 0] = 0 # remove power coefficients\n",
    "        engine = Synthesizer(MLSADF(order=order, alpha=alpha), hopsize=hop_length)\n",
    "        b = pysptk.mc2b(mc.astype(np.float64), alpha=alpha)\n",
    "        waveform = engine.synthesis(x, b)\n",
    "    else:\n",
    "        spectrogram = pysptk.mc2sp(\n",
    "            mc.astype(np.float64), alpha=alpha, fftlen=fftlen)\n",
    "        waveform = pyworld.synthesize(\n",
    "            f0, spectrogram, aperiodicity, frame_sample, frame_period)\n",
    "        \n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_path, tgt_path) in enumerate(zip(src_speaker.test_paths, tgt_speaker.test_paths)):\n",
    "    print(\"{}-th sample\".format(i+1))\n",
    "    wo_MLPG = test_one_utt(src_path, tgt_path, disable_mlpg=True)\n",
    "    w_MLPG = test_one_utt(src_path, tgt_path, disable_mlpg=False)\n",
    "    src, _ = librosa.load(src_path, sr=fs, dtype=float64)\n",
    "    tgt, _ = librosa.load(tgt_path, sr=fs, dtype=float64)\n",
    "    \n",
    "    print(\"Source:\", basename(src_path))\n",
    "    IPython.display.display(Audio(src, rate=fs))\n",
    "    print(\"Target:\", basename(tgt_path))\n",
    "    IPython.display.display(Audio(tgt, rate=fs))\n",
    "    print(\"w/o MLPG\")\n",
    "    IPython.display.display(Audio(wo_MLPG, rate=fs))\n",
    "    print(\"w/ MLPG\")\n",
    "    IPython.display.display(Audio(w_MLPG, rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
